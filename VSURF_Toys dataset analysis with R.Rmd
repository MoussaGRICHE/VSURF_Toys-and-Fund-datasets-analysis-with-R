---
title: "VSURF_Toys dataset analysis with R"
output: pdf_document
date: '2022-10-21'
---


## DATA PREPARATION

### Upload Data

```{r}
library(VSURF)
data(toys)
```

### Splitting toys dataset into Train and Test Datasets:

```{r}

toys.Y <- toys$y
toys.X <- toys$x

## 80% of the sample size
smp_size <- floor(0.8*(nrow(toys$x)))

## set the seed to make the partition reproducible
set.seed(1111111)
sample.x <- sample(seq_len(nrow(toys$x)), size = smp_size)

toys.y.train <- as.integer(toys.Y[sample.x])
toys.x.train <- as.data.frame(toys.X[sample.x, ])

toys.y.test <- as.integer(toys.Y[sample.x])
toys.x.test <- as.data.frame(toys.X[sample.x, ])

```

```{r}
toys.x.train
```



# 1- Perform a linear model and apply a variable selection procedure
## 1.1: Perform a linear model

```{r}
toys.lm1 <- lm(toys.y.train~., data=toys.x.train)
summary(toys.lm1)
```

## 1.2: apply a variable selection procedure
### 1.2.1: Variable selection with Lasso:
```{r}
library(glmnet)
#perform k-fold cross-validation to find optimal lambda value
cv_toys <- cv.glmnet(as.matrix(toys.x.train), toys.y.train, alpha = 1)

#find optimal lambda value that minimizes test MSE
best_lambda_Lasso <- cv_toys$lambda.min

#find coefficients of LASSO best model
toys.LASSO <- glmnet(toys.x.train, toys.y.train, alpha = 1, lambda = best_lambda_Lasso)
coef(toys.LASSO)

```

### 1.2.3: Variable selection with Ridge:
```{r}
#perform k-fold cross-validation to find optimal lambda value
cv_toys <- cv.glmnet(as.matrix(toys.x.train), toys.y.train, alpha = 0)

#find optimal lambda value that minimizes test MSE
best_lambda_Ridge <- cv_toys$lambda.min

toys.Ridge = glmnet(toys.x.train, toys.y.train, nlambda = 25, alpha = 0, family = 'gaussian', lambda = best_lambda_Ridge)


coef(toys.Ridge)
```

# 2: Evaluate the quality of this model by test error:
## 2.1: Lasso selection
```{r}
#use fitted best model to make predictions
toys.LASSO.y_predicted <- predict(toys.LASSO, newx=as.matrix(toys.x.test))

#find Mean Squared Error
MSE_LASSO <- mean((toys.y.test - toys.LASSO.y_predicted)^2)

cat("Mean squared error of the LASSO model equal to:", MSE_LASSO )

```

## 2.2:Ridge selection:
```{r}
#use fitted best model to make predictions
toys.Ridge.y_predicted <- predict(toys.Ridge, newx=as.matrix(toys.x.test))

#find Mean Squared Error
MSE_Ridge <- mean((toys.y.test - toys.Ridge.y_predicted)^2)

cat("Mean squared error of the Ridge model equal to:", MSE_Ridge )

```
# 3:
## 3.1: CART model
```{r}
library(rpart)
library(rpart.plot)
toys.CART <- rpart(toys.y.train~. , data=toys.x.train)
rpart.plot(toys.CART)
summary(toys.CART)
```




## 3.2: Random forest model
```{r}
library(randomForest)
toys.RF=randomForest(toys.y.train~. , data=toys.x.train)
summary(toys.RF)
toys.RF$importance
varImpPlot(toys.RF)
```




### 3.3.1: Evaluation of CART model's performance
```{r}
toys.CART_predicted = predict(toys.CART,  toys.x.test)
toys.CART.mse = mean( (toys.CART_predicted - toys.y.test)^2 )
cat("Mean squared error of the CART model equal to:",toys.CART.mse )
```



### 3.3.1: Evaluation of Random forest model's performance
```{r}
toys.RF_predicted = predict(toys.RF, toys.x.test)
toys.RF.mse = mean( (toys.RF_predicted - toys.y.test)^2 )
cat("Mean squared error of the random forest model equal to:",toys.RF.mse )
```

# 4:
## 4.1: Explination of VSURF procedure




## 4.2: VSURF procedure
```{r}
toys.VSURF=VSURF(toys.x.train, as.factor(toys.y.train))
```


```{r}
toys.VSURF$varselect.thres
```
```{r}
toys.VSURF$varselect.interp
```
```{r}
toys.VSURF$varselect.pred
```

## 4.3: Final model based on VSURF
```{r}
toys.VSURF$err.thres
mean(toys.VSURF$err.interp)
mean(toys.VSURF$err.pred)
```

```{r}

```



## 4.4: Evaluation the quality of this final model
```{r}
toys.VSURF_predicted = predict(toys.VSURF, toys.x.test)
toys.VSURF_predicted
toys.VSURF_predicted <- as.double(unlist(toys.VSURF_predicted))
toys.VSURF_predicted
toys.y.test
toys.VSURF.mse = mean( (toys.VSURF_predicted - toys.y.test)^2 )
cat("Mean squared error of the VSURF model equal to:",toys.VSURF.mse )
```

# 5: What can you say?


# 6: Repeat also of this 50 times. What can you say?




